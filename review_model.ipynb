{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings as w\n",
    "w.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the huge dataset into small chunks\n",
    "df_reader = pd.read_json('Clothing_Shoes_and_Jewelry.json', lines = True, chunksize = 1000000 )\n",
    "\n",
    "counter = 1\n",
    "for chunk in df_reader:\n",
    "    new_df = pd.DataFrame(chunk[['overall','reviewText','summary']])\n",
    "    new_df1 = new_df[new_df['overall'] == 5].sample(4000)\n",
    "    new_df2 = new_df[new_df['overall'] == 4].sample(4000)\n",
    "    new_df3 = new_df[new_df['overall'] == 3].sample(8000)\n",
    "    new_df4 = new_df[new_df['overall'] == 2].sample(4000)\n",
    "    new_df5 = new_df[new_df['overall'] == 1].sample(4000)\n",
    "    \n",
    "    new_df6 = pd.concat([new_df1,new_df2,new_df3,new_df4,new_df5], axis = 0, ignore_index = True)\n",
    "    \n",
    "    new_df6.to_csv(str(counter)+\".csv\", index = False)\n",
    "    \n",
    "    new_df = None\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 794049 entries, 0 to 794048\n",
      "Data columns (total 4 columns):\n",
      " #   Column                                                                                                                                                                                                                                                                                               Non-Null Count   Dtype  \n",
      "---  ------                                                                                                                                                                                                                                                                                               --------------   -----  \n",
      " 0   overall                                                                                                                                                                                                                                                                                              792000 non-null  float64\n",
      " 1   reviewText                                                                                                                                                                                                                                                                                           791406 non-null  object \n",
      " 2   summary                                                                                                                                                                                                                                                                                              791747 non-null  object \n",
      " 3   \r\n",
      "            What can i say, they are beautiful !! Beautifully made, and look gorgeous on, and comfortable to wear also look very expensive, at the price they are, they are amazing !! People comment on how lovely and where i got them from. So well done, i love them and thank you.\r\n",
      "          2049 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 24.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# combining those chunks into a single CSV file i.e balanced_reviews.csv\n",
    "from glob import glob\n",
    "filenames = glob('*.csv')\n",
    "dataframes = [pd.read_csv(f, encoding='cp1252') for f in filenames]\n",
    "frame = pd.concat(dataframes, axis = 0, ignore_index = True)\n",
    "frame.to_csv('balanced_reviews.csv', index = False)\n",
    "frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    AS ALWAYS CARHARTT MEANS QUALITY!\n",
       "1    After ordering pair upon pair of tall black bo...\n",
       "2    Product is sturdy, looks good and displays the...\n",
       "3                  Great coat, very warm and well made\n",
       "4                          Perfect for my Disneybound!\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the dataset and performing the data analysis\n",
    "df = pd.read_csv(r'balanced_reviews.csv')\n",
    "# df.columns.tolist()\n",
    "\n",
    "# df['overall'].value_counts()\n",
    "\n",
    "# df.shape\n",
    "\n",
    "# df.isnull().any(axis = 0)\n",
    "\n",
    "# df.isnull().any(axis = 1)\n",
    "\n",
    "# df[df.isnull().any(axis = 1)]\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "df['overall'] != 3\n",
    "\n",
    "df = df[df['overall'] != 3]\n",
    "df\n",
    "\n",
    "df['overall'].value_counts()\n",
    "\n",
    "df['Positivity'] = np.where(df['overall'] > 3,1,0)\n",
    "\n",
    "df['Positivity'].value_counts()\n",
    "\n",
    "# df.columns\n",
    "\n",
    "df['reviewText'].head()\n",
    "\n",
    "# len(df['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing the data cleaning with the help of Natural Language tool Kit with the help of stopwords concept\n",
    "import nltk\n",
    "\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "df['reviewText'][0]\n",
    "\n",
    "df.iloc[0, 1]\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(0, 527357):\n",
    "    print(i)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df.iloc[i, 1])\n",
    "    \n",
    "    review = review.lower()\n",
    "    \n",
    "    review = review.split()\n",
    "    \n",
    "    review = [word for word in review if not word in stopwords.words('english')]\n",
    "    \n",
    "    ps =  PorterStemmer()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review]\n",
    "    \n",
    "    review = \" \".join(review)\n",
    "    \n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "features = CountVectorizer().fit_transform(corpus)\n",
    "labels = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words model\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(df['reviewText'], df['Positivity'], random_state = 42 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<395517x65387 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9681144 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer().fit(features_train)\n",
    "vect.vocabulary_\n",
    "len(vect.get_feature_names())\n",
    "features_train_vectorized = vect.transform(features_train)\n",
    "# features_train_vectorized.toarray()\n",
    "features_train_vectorized\n",
    "# vect.get_feature_names()[15000:15005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting and prediction of model with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(features_train_vectorized, labels_train)\n",
    "predictions = model.predict(vect.transform(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use of Tfid Vectorizer as an ideal vectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(min_df = 5).fit(features_train)\n",
    "features_train_vectorized = vect.transform(features_train)\n",
    "# vect\n",
    "# features_train_vectorized.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9028601296454845"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generation of confusion matrix and estimating the roc accuracy score with the help of the test data and predicted data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "confusion_matrix(labels_test, predictions)\n",
    "roc_auc_score(labels_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumping the model into the pickle file and the vectorized vocabulary into a new pickle file i.e feature.pkl \n",
    "import pickle as p\n",
    "pkl_filename = \"pickle_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    p.dump(model, file)\n",
    "p.dump(vect.vocabulary_, open('feature.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9028601296454845"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting and finding the roc accuracy score for that pickle file\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    pickle_model = p.load(file)\n",
    "\n",
    "pred = pickle_model.predict(vect.transform(features_test))\n",
    "roc_auc_score(labels_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
